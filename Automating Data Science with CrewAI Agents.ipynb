{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOMATING DATA SCIENCE WITH CREWAI AGENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Documentation: https://docs.crewai.com/introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING KEY LIBRARIES & THE `NotebookCodeExecutor` TOOL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we build our Crew, we need to install the necessary libraries and import them.\n",
    "\n",
    "*   **crewai:** The core library for creating agents, tasks, and crews.\n",
    "*   **openai:** Required if using OpenAI models as the brain for our agents.\n",
    "*   **python-dotenv:** To manage API keys securely.\n",
    "*   **pandas:** Although the agents will use pandas via code execution, we might need it here for initial setup or data loading verification.\n",
    "*   **langchain_openai:** CrewAI uses LangChain components, so we need this for the OpenAI LLM integration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall crewai -y\n",
    "!pip install crewai --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import crewAI\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai.tools import BaseTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown, Image\n",
    "\n",
    "# Load environment variables (especially API keys)\n",
    "load_dotenv()\n",
    "\n",
    "# Configure API Key, which is essential for AI agents to use OpenAI models\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize the LLM for the agents\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini-2025-04-14\", api_key = openai_api_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to print markdowns\n",
    "def print_markdown(text):\n",
    "    \"\"\"Displays text as Markdown in Jupyter.\"\"\"\n",
    "    display(Markdown(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "The Notebook Executor tool will:\n",
    "1.  Accept Python code as a string.\n",
    "2.  Optionally accept a list of required Python libraries.\n",
    "3.  Attempt to install the required libraries using `pip` within the current environment.\n",
    "4.  Execute the provided Python code directly in the **notebook's global scope** using `exec()`. This allows interaction with existing variables like `shared_df`.\n",
    "5.  Capture any output printed by the code.\n",
    "6.  Return the captured output or any error messages (from installation or execution).\n",
    "\n",
    "**üö® SECURITY WARNING:** This tool executes arbitrary code directly in your environment using `exec(code, globals())`. Like `unsafe_mode=True`, this carries significant security risks. Only use it in trusted environments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebookExecutor import NotebookCodeExecutor, NotebookCodeExecutorSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's load the data into a shared DataFrame that our tool can access\n",
    "# This simulates the data being available in the execution environment\n",
    "import pandas as pd\n",
    "file_path = \"Supplement_Sales_Weekly.csv\"\n",
    "shared_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test the Notebook Code executor tool \n",
    "# Let's define a basic function that adds two numbers\n",
    "def add_numbers(a,b):\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's instantiate the custom tool\n",
    "notebook_executor_tool = NotebookCodeExecutor(namespace=globals())\n",
    "print(\"‚úÖ Custom tool 'NotebookCodeExecutor' instantiated with notebook's global namespace.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the tool\n",
    "test_code = \"print(add_numbers(1,2))\"\n",
    "print(\"\\nTesting tool:\\n\")\n",
    "print(notebook_executor_tool.run(code = test_code))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINING THE AGENTS WITH CODE GENERATION FOCUS\n",
    "\n",
    "We define the agents, emphasizing their ability to *write* Python code for their tasks and then use the `notebook_executor_tool` to run it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Data Science Planner Agent (no tool needed)\n",
    "planner_agent = Agent(role = \"Lead Data Scientist and Planner\",\n",
    "                      goal = (\"Analyze the objective (predict 'Units Sold') assuming data is in a global pandas DataFrame 'shared_df'. \"\n",
    "                              \"Create a step-by-step plan for regression analysis. Instruct subsequent agents on the GOALS for each step.\"\n",
    "                              \"(e.g., inspect data, preprocess, model, evaluate) and tell them to use the 'Notebook Code Executor' tool \"\n",
    "                              \"to WRITE and EXECUTE the necessary Python code.\"),\n",
    "                    backstory = (\"Experienced data scientist planning ML projects. Knows data is in 'shared_df' and agents will write and execute code using a tool.\"),\n",
    "                    llm = llm,\n",
    "                    allow_delegation = False,\n",
    "                    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Data Analysis and Preprocessing Agent (needs access to notebook_executer_tool to generate code)\n",
    "analyst_preprocessor_agent = Agent(role = \"Data Analysis and Preprocessing Expert\",\n",
    "                                   goal = (\n",
    "        \"Follow the plan for data analysis and preprocessing. **Write the necessary Python code** using pandas and scikit-learn \"\n",
    "        \"to operate on the global pandas DataFrame 'shared_df'. Your code must perform inspection (shape, info, nulls, describe), \"\n",
    "        \"handle date/identifiers (convert 'Date', sort, drop 'Date'/'Product Name'), encode categoricals (OneHotEncode 'Platform' modifying 'shared_df'), \"\n",
    "        \"and finally **create the global variables X_train, X_test, y_train, y_test** from 'shared_df' using an 80/20 split (shuffle=False). \"\n",
    "        \"Use the 'Notebook Code Executor' tool to execute the code you write. Ensure your generated code includes print statements for key results.\"),\n",
    "    \n",
    "                                   backstory = (\n",
    "        \"Meticulous analyst skilled in writing pandas/sklearn code. Uses the 'Notebook Code Executor' tool to run the generated code. \"\n",
    "        \"Knows data is in global 'shared_df' and must create global train/test variables.\"),\n",
    "                                   llm = llm,\n",
    "                                   tools = [notebook_executor_tool],  # Assign the custom tool explicitly\n",
    "                                   allow_delegation = False,\n",
    "                                   verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Modeling and Evaluation Agent (needs access to notebook_executer_tool to generate code)\n",
    "modeler_evaluator_agent = Agent(role = \"Machine Learning Modeler and Evaluator\",\n",
    "                                goal = (\n",
    "        \"Follow the plan for modeling and evaluation. **Write the necessary Python code** using scikit-learn. \"\n",
    "        \"Assume global variables X_train, X_test, y_train, y_test exist. Your code must train a RandomForestRegressor(random_state=42), \"\n",
    "        \"make predictions on X_test, calculate and print evaluation metrics (MAE, MSE, RMSE, R¬≤), and print the top 10 feature importances. \"\n",
    "        \"Use the 'Notebook Code Executor' tool to execute the code you write. \"\n",
    "        \"Finally, include the exact Python code you generated and executed in your final response, formatted in a markdown block.\"\n",
    "    ),\n",
    "                                backstory = (\n",
    "        \"ML engineer specialized in regression. Writes scikit-learn code and uses the 'Notebook Code Executor' tool to run it. \"\n",
    "        \"Expects global train/test split variables (X_train etc.) to be available.\"\n",
    "    ),\n",
    "    llm = llm,\n",
    "    tools = [notebook_executor_tool],  # Assign the custom tool explicitly\n",
    "    allow_delegation = False,\n",
    "    verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚úÖ CrewAI Agents defined, focusing on code generation.\")\n",
    "print(f\"- {planner_agent.role}\")\n",
    "print(f\"- {analyst_preprocessor_agent.role} (Tool: {analyst_preprocessor_agent.tools[0].name})\")\n",
    "print(f\"- {modeler_evaluator_agent.role} (Tool: {modeler_evaluator_agent.tools[0].name})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINING KEY TASKS & RESPONSIBLE AGENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Tasks now provide high-level instructions, guiding the agents on the objectives for each step and reminding them to generate the necessary Python code and execute it using the `Notebook Code Executor` tool, ensuring interaction with the global state (`shared_df`, `X_train`, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Planning Task (Stays largely the same, instructs agents on GOALS)\n",
    "planning_task = Task(\n",
    "    description = (\n",
    "        \"1. Goal: Create a plan for regression predicting 'Units Sold'.\\n\"\n",
    "        \"2. Data Context: Global pandas DataFrame 'shared_df' is available.\\n\"\n",
    "        \"3. Plan Steps: Outline sequence, instructing agents on their GOALS for each step and to use the 'Notebook Code Executor' tool to WRITE and RUN Python code:\\n\"\n",
    "        \"    a. Goal: Inspect global 'shared_df' (shape, info, nulls, describe).\\n\"\n",
    "        \"    b. Goal: Preprocess global 'shared_df' (handle Date [to_datetime, sort, drop], drop identifiers ['Product Name'], OneHotEncode 'Platform' [update 'shared_df'], create global X/y vars, create global train/test split vars X_train/test, y_train/test [80/20, shuffle=False]).\\n\"\n",
    "        \"    c. Goal: Train RandomForestRegressor using global X_train, y_train (use random_state=42).\\n\"\n",
    "        \"    d. Goal: Evaluate model on global X_test (predict, calc & print MAE, MSE, RMSE, R2).\\n\"\n",
    "        \"    e. Goal: Extract & print top 10 feature importances from the trained model.\\n\"\n",
    "        \"5. Output: Numbered plan focusing on the objectives for each data science step.\"\n",
    "    ),\n",
    "    expected_output = (\n",
    "        \"Numbered plan outlining the data science goals for subsequent agents, reminding them to generate code and use the 'Notebook Code Executor' tool, interacting with global variables like 'shared_df' and 'X_train'.\"\n",
    "    ),\n",
    "    agent = planner_agent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Data Analysis and Preprocessing Task (High-level instructions)\n",
    "data_analysis_preprocessing_task = Task(\n",
    "    description = (\n",
    "        \"Follow the analysis/preprocessing plan. Your goal is to inspect and prepare the global 'shared_df' DataFrame and create global training/testing variables. \"\n",
    "        \"You MUST **generate Python code** to achieve this and then execute it using the 'Notebook Code Executor' tool. \"\n",
    "        \"Specifically, your generated code needs to:\\n\"\n",
    "        \"1. Inspect the 'shared_df' DataFrame (print shape, info(), isnull().sum(), describe()).\\n\"\n",
    "        \"2. Convert 'Date' column in 'shared_df' to datetime objects, sort 'shared_df' by 'Date', then drop the 'Date' and 'Product Name' columns from 'shared_df'.\\n\"\n",
    "        \"3. One-Hot Encode the 'Platform' column in 'shared_df' (use pd.get_dummies, drop_first=True). **Crucially, ensure 'shared_df' DataFrame variable is updated with the result of the encoding.**\\n\"\n",
    "        \"4. Create a global variable 'y' containing the 'Units Sold' column from 'shared_df'.\\n\"\n",
    "        \"5. Create a global variable 'X' containing the remaining columns from the updated 'shared_df' (after dropping 'Units Sold').\\n\"\n",
    "        \"6. Split 'X' and 'y' into global variables: 'X_train', 'X_test', 'y_train', 'y_test' using an 80/20 split with `shuffle=False`. Ensure these four variables are created in the global scope.\\n\"\n",
    "        \"Make sure your generated code includes necessary imports (like pandas, train_test_split) and print statements for verification (e.g., printing shapes of created variables like X_train.shape).\"\n",
    "        # \"Remember to pass the required libraries (e.g., ['pandas', 'scikit-learn']) to the tool if your code uses them, although they should be pre-imported in this notebook.\" # Optional hint, often the agent figures out imports\n",
    "    ),\n",
    "    expected_output = (\n",
    "        \"Output from the 'Notebook Code Executor' tool showing the successful execution of agent-generated code. This includes printouts confirming:\\n\"\n",
    "        \"- Initial data inspection results for 'shared_df'.\\n\"\n",
    "        \"- Confirmation of DataFrame modifications (e.g., shape after encoding).\\n\"\n",
    "        \"- Confirmation of the creation and shapes of global variables X, y, X_train, X_test, y_train, y_test.\"\n",
    "    ),\n",
    "    agent = analyst_preprocessor_agent,\n",
    "    tools = [notebook_executor_tool],  # Explicitly list tool\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Modeling and Evaluation Task (High-level instructions)\n",
    "modeling_evaluation_task = Task(\n",
    "    description = (\n",
    "        \"Follow the modeling/evaluation plan. Your goal is to train a model, evaluate it, and report results. \"\n",
    "        \"You MUST **generate Python code** assuming global variables X_train, X_test, y_train, y_test exist, and execute it using the 'Notebook Code Executor' tool. \"\n",
    "        \"Specifically, your generated code needs to:\\n\"\n",
    "        \"1. Train a `RandomForestRegressor` model (use `random_state=42`) using the global `X_train` and `y_train` variables. Store the trained model in a global variable named `trained_model`.\\n\"\n",
    "        \"2. Make predictions on the global `X_test` variable.\\n\"\n",
    "        \"3. Calculate and print the MAE, MSE, RMSE, and R-squared metrics by comparing predictions against the global `y_test` variable.\\n\"\n",
    "        \"4. Calculate and print the top 10 feature importances from the trained model (using `X_train.columns` for feature names).\\n\"\n",
    "        \"Make sure your generated code includes necessary imports (like RandomForestRegressor, metrics functions from sklearn.metrics, numpy, pandas) and print statements for all results.\\n\"\n",
    "        \"Finally, include the exact Python code you generated and executed within a markdown code block (```python...```) in your final response.\"\n",
    "        # \"Remember to pass required libraries like ['scikit-learn', 'pandas', 'numpy'] to the tool if needed.\" # Optional hint\n",
    "    ),\n",
    "    expected_output = (\n",
    "        \"Output from the 'Notebook Code Executor' tool showing the successful execution of agent-generated code, including:\\n\"\n",
    "        \"- Printed regression metrics (MAE, MSE, RMSE, R¬≤).\\n\"\n",
    "        \"- Printed top 10 feature importances.\\n\"\n",
    "        \"The final response MUST also contain a markdown code block (```python...```) showing the exact Python code that was generated and executed for these steps.\"\n",
    "    ),\n",
    "    agent = modeler_evaluator_agent,\n",
    "    tools = [notebook_executor_tool],  # Explicitly list tool\n",
    ")\n",
    "\n",
    "print(\"‚úÖ CrewAI Tasks defined with high-level instructions for code generation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATING AND RUNNING THE CREW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assemble the crew. The agents will now attempt to generate and execute the code needed for their tasks using the `NotebookCodeExecutor` tool. This may take longer and require more careful observation of the verbose output to ensure correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's Create the Crew\n",
    "regression_crew = Crew(\n",
    "    agents = [planner_agent, analyst_preprocessor_agent, modeler_evaluator_agent],\n",
    "    tasks = [planning_task, data_analysis_preprocessing_task, modeling_evaluation_task],\n",
    "    process = Process.sequential,\n",
    "    verbose = 1,  # Use detailed output to see agent thoughts and tool usage\n",
    "    output_log_file = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kick off the crew execution!\n",
    "print(\"Starting the Crew execution (Agents will generate code)...\")\n",
    "\n",
    "# Ensure the initial DataFrame exists before starting\n",
    "crew_result = regression_crew.kickoff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nüèÅ Crew execution finished.\")\n",
    "print(\"\\nCrew Final Result (Output of last task):\")\n",
    "print(\"========================================\")\n",
    "\n",
    "print_markdown(crew_result.raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Data Analysis and Preprocessing Agent (needs tool, generates code)\n",
    "analyst_preprocessor_agent = Agent(role = \"Data Analysis and Preprocessing Expert\",\n",
    "                                   goal = (\n",
    "        \"Follow the plan for data analysis and preprocessing. **Write the necessary Python code** using pandas and scikit-learn \"\n",
    "        \"to operate on the global pandas DataFrame 'shared_df'. Your code must perform inspection (shape, info, nulls, describe), impute missing values, \"\n",
    "        \"handle date/identifiers (convert 'Date', sort, drop 'Date'/'Product Name'), encode categoricals (OneHotEncode 'Platform' modifying 'shared_df'), \"\n",
    "        \"and finally **create the global variables X_train, X_test, y_train, y_test** from 'shared_df' using an 80/20 split (shuffle=True). \"\n",
    "        \"Use the 'Notebook Code Executor' tool to execute the code you write. Ensure your generated code includes print statements for key results.\"),\n",
    "    \n",
    "                                   backstory = (\n",
    "        \"Meticulous analyst skilled in writing pandas/sklearn code. Uses the 'Notebook Code Executor' tool to run the generated code. \"\n",
    "        \"Knows data is in global 'shared_df' and must create global train/test variables.\"),\n",
    "                                   llm = llm,\n",
    "                                   tools = [notebook_executor_tool],  # Assign the custom tool explicitly\n",
    "                                   allow_delegation = False,\n",
    "                                   verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_df = pd.read_csv(file_path)\n",
    "\n",
    "planner_agent = Agent(\n",
    "    role = \"Lead Data Scientist and Planner\",\n",
    "    goal = (\n",
    "        \"Analyze the objective (predict 'Units Sold') assuming data is in a global pandas DataFrame 'shared_df'. \"\n",
    "        \"Create a step-by-step plan for regression analysis. Instruct subsequent agents on the GOALS for each step \"\n",
    "        \"(e.g., inspect data, preprocess, model, evaluate) and tell them to use the 'Notebook Code Executor' tool \"\n",
    "        \"to WRITE and EXECUTE the necessary Python code.\"\n",
    "    ),\n",
    "    backstory = (\n",
    "        \"Experienced data scientist planning ML projects. Knows data is in 'shared_df' and agents will write and execute code using a tool.\"\n",
    "    ),\n",
    "    llm = llm,\n",
    "    allow_delegation = False,\n",
    "    verbose = True,\n",
    ")\n",
    "\n",
    "# Define the Data Analysis and Preprocessing Agent (needs tool, generates code)\n",
    "analyst_preprocessor_agent = Agent(\n",
    "    role = \"Data Analysis and Preprocessing Expert\",\n",
    "    goal=(\n",
    "        \"Follow the plan for data analysis and preprocessing. **Write the necessary Python code** using pandas and scikit-learn \"\n",
    "        \"to operate on the global pandas DataFrame 'shared_df'. Your code must perform inspection (shape, info, nulls, describe), \"\n",
    "        \"handle date/identifiers (convert 'Date', sort, drop 'Date'/'Product Name'), encode categoricals (OneHotEncode 'Platform' modifying 'shared_df'), \"\n",
    "        \"and finally **create the global variables X_train, X_test, y_train, y_test** from 'shared_df' using an 80/20 split (shuffle=False). \"\n",
    "        \"Use the 'Notebook Code Executor' tool to execute the code you write. Ensure your generated code includes print statements for key results.\"\n",
    "    ),\n",
    "    backstory = (\n",
    "        \"Meticulous analyst skilled in writing pandas/sklearn code. Uses the 'Notebook Code Executor' tool to run the generated code. \"\n",
    "        \"Knows data is in global 'shared_df' and must create global train/test variables.\"\n",
    "    ),\n",
    "    llm = llm,\n",
    "    tools = [notebook_executor_tool],  # Assign the custom tool explicitly\n",
    "    allow_delegation = False,\n",
    "    verbose = True,\n",
    ")\n",
    "\n",
    "# Define the Modeling and Evaluation Agent (needs tool, generates code)\n",
    "modeler_evaluator_agent = Agent(\n",
    "    role = \"Machine Learning Modeler and Evaluator\",\n",
    "    goal = (\n",
    "        \"Follow the plan for modeling and evaluation. **Write the necessary Python code** using scikit-learn. \"\n",
    "        \"Assume global variables X_train, X_test, y_train, y_test exist. Your code must train both a Decision Tree model and a Random Forest model, \"\n",
    "        \"make predictions on X_test with both models, calculate and print evaluation metrics (MAE, MSE, RMSE, R¬≤) for both models, compare their performance, \"\n",
    "        \"and print the top 10 feature importances for each model. \"\n",
    "        \"Use the 'Notebook Code Executor' tool to execute the code you write. \"\n",
    "        \"Finally, include the exact Python code you generated and executed in your final response, formatted in a markdown block.\"\n",
    "    ),\n",
    "    backstory = (\n",
    "        \"ML engineer specialized in regression. Writes code and uses the 'Notebook Code Executor' tool to run it. \"\n",
    "        \"Expects global train/test split variables (X_train etc.) to be available.\"\n",
    "    ),\n",
    "    llm = llm,\n",
    "    tools = [notebook_executor_tool],  # Assign the custom tool explicitly\n",
    "    allow_delegation = False,\n",
    "    verbose = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "planning_task = Task(\n",
    "    description = (\n",
    "        \"1. Goal: Create plan for regression predicting 'Units Sold'.\\n\"\n",
    "        \"2. Data Context: Global pandas DataFrame 'shared_df' is available.\\n\"\n",
    "        \"3. Plan Steps: Outline sequence, instructing agents on their GOALS for each step and to use the 'Notebook Code Executor' tool to WRITE and RUN Python code:\\n\"\n",
    "        \"    a. Goal: Inspect global 'shared_df' (shape, info, nulls, describe).\\n\"\n",
    "        \"    b. Goal: Preprocess global 'shared_df' (handle Date [to_datetime, sort, drop], drop identifiers ['Product Name'], OneHotEncode 'Platform' [update 'shared_df'], create global X/y vars, create global train/test split vars X_train/test, y_train/test [80/20, shuffle=False]).\\n\"\n",
    "        \"    c. Goal: Train both Decision Tree and Random Forest models using global X_train, y_train (use random_state=42).\\n\"\n",
    "        \"    d. Goal: Evaluate both models on global X_test (predict, calc & print MAE, MSE, RMSE, R2).\\n\"\n",
    "        \"    e. Goal: Compare performance between Decision Tree and Random Forest models.\\n\"\n",
    "        \"    f. Goal: Extract & print top 10 feature importances from both trained models.\\n\"\n",
    "        \"5. Output: Numbered plan focusing on the objectives for each data science step.\"\n",
    "    ),\n",
    "    expected_output = (\n",
    "        \"Numbered plan outlining the data science goals for subsequent agents, reminding them to generate code and use the 'Notebook Code Executor' tool, interacting with global variables like 'shared_df' and 'X_train'.\"\n",
    "    ),\n",
    "    agent=planner_agent,\n",
    ")\n",
    "\n",
    "# Define the Data Analysis and Preprocessing Task (High-level instructions)\n",
    "data_analysis_preprocessing_task = Task(\n",
    "    description = (\n",
    "        \"Follow the analysis/preprocessing plan. Your goal is to inspect and prepare the global 'shared_df' DataFrame and create global training/testing variables. \"\n",
    "        \"You MUST **generate Python code** to achieve this and then execute it using the 'Notebook Code Executor' tool. \"\n",
    "        \"Specifically, your generated code needs to:\\n\"\n",
    "        \"1. Inspect the 'shared_df' DataFrame (print shape, info(), isnull().sum(), describe()).\\n\"\n",
    "        \"2. Convert 'Date' column in 'shared_df' to datetime objects, sort 'shared_df' by 'Date', then drop the 'Date' and 'Product Name' columns from 'shared_df'.\\n\"\n",
    "        \"3. One-Hot Encode the 'Platform' column in 'shared_df' (use pd.get_dummies, drop_first=True). **Crucially, ensure 'shared_df' DataFrame variable is updated with the result of the encoding.**\\n\"\n",
    "        \"4. Create a global variable 'y' containing the 'Units Sold' column from 'shared_df'.\\n\"\n",
    "        \"5. Create a global variable 'X' containing the remaining columns from the updated 'shared_df' (after dropping 'Units Sold').\\n\"\n",
    "        \"6. Split 'X' and 'y' into global variables: 'X_train', 'X_test', 'y_train', 'y_test' using an 80/20 split with `shuffle=False`. Ensure these four variables are created in the global scope.\\n\"\n",
    "        \"Make sure your generated code includes necessary imports (like pandas, train_test_split) and print statements for verification (e.g., printing shapes of created variables like X_train.shape).\"\n",
    "        # \"Remember to pass the required libraries (e.g., ['pandas', 'scikit-learn']) to the tool if your code uses them, although they should be pre-imported in this notebook.\" # Optional hint, often the agent figures out imports\n",
    "    ),\n",
    "    expected_output = (\n",
    "        \"Output from the 'Notebook Code Executor' tool showing the successful execution of agent-generated code. This includes printouts confirming:\\n\"\n",
    "        \"- Initial data inspection results for 'shared_df'.\\n\"\n",
    "        \"- Confirmation of DataFrame modifications (e.g., shape after encoding).\\n\"\n",
    "        \"- Confirmation of the creation and shapes of global variables X, y, X_train, X_test, y_train, y_test.\"\n",
    "    ),\n",
    "    agent = analyst_preprocessor_agent,\n",
    "    tools = [notebook_executor_tool],  # Explicitly list tool\n",
    ")\n",
    "\n",
    "# Define the Modeling and Evaluation Task (High-level instructions)\n",
    "modeling_evaluation_task = Task(\n",
    "    description = (\n",
    "        \"Follow the modeling/evaluation plan. Your goal is to train both Decision Tree and Random Forest models, evaluate them, compare their performance, and report results. \"\n",
    "        \"You MUST **generate Python code** assuming global variables X_train, X_test, y_train, y_test exist, and execute it using the 'Notebook Code Executor' tool. \"\n",
    "        \"Specifically, your generated code needs to:\\n\"\n",
    "        \"1. Train a `DecisionTreeRegressor` model (use `random_state=42`) using the global `X_train` and `y_train` variables. Store the trained model in a global variable named `dt_model`.\\n\"\n",
    "        \"2. Train a `RandomForestRegressor` model (use `random_state=42`) using the global `X_train` and `y_train` variables. Store the trained model in a global variable named `rf_model`.\\n\"\n",
    "        \"3. Make predictions on the global `X_test` variable with both models.\\n\"\n",
    "        \"4. Calculate and print the MAE, MSE, RMSE, and R-squared metrics for both models by comparing predictions against the global `y_test` variable.\\n\"\n",
    "        \"5. Compare the performance of both models and highlight which one performs better and why.\\n\"\n",
    "        \"6. Calculate and print the top 10 feature importances from both trained models (using `X_train.columns` for feature names).\\n\"\n",
    "        \"Make sure your generated code includes necessary imports (like DecisionTreeRegressor, RandomForestRegressor, metrics functions from sklearn.metrics, numpy, pandas) and print statements for all results.\\n\"\n",
    "        \"Finally, include the exact Python code you generated and executed within a markdown code block (```python...```) in your final response.\"\n",
    "        # \"Remember to pass required libraries like ['scikit-learn', 'pandas', 'numpy'] to the tool if needed.\" # Optional hint\n",
    "    ),\n",
    "    expected_output = (\n",
    "        \"Output from the 'Notebook Code Executor' tool showing the successful execution of agent-generated code, including:\\n\"\n",
    "        \"- Printed regression metrics (MAE, MSE, RMSE, R¬≤) for both Decision Tree and Random Forest models.\\n\"\n",
    "        \"- Comparison of performance between the two models.\\n\"\n",
    "        \"- Printed top 10 feature importances for both models.\\n\"\n",
    "        \"The final response MUST also contain a markdown code block (```python...```) showing the exact Python code that was generated and executed for these steps.\"\n",
    "    ),\n",
    "    agent = modeler_evaluator_agent,\n",
    "    tools = [notebook_executor_tool],  # Explicitly list tool\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regression_crew = Crew(\n",
    "    agents = [planner_agent, analyst_preprocessor_agent, modeler_evaluator_agent],\n",
    "    tasks = [planning_task, data_analysis_preprocessing_task, modeling_evaluation_task],\n",
    "    process = Process.sequential,\n",
    "    verbose = 1,  # Use detailed output to see agent thoughts and tool usage\n",
    "    output_log_file = True,\n",
    ")\n",
    "\n",
    "# Kick off the crew execution!\n",
    "print(\"Starting the Crew execution (Agents will generate code)...\")\n",
    "\n",
    "# Ensure the initial DataFrame exists before starting\n",
    "crew_result = regression_crew.kickoff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nüèÅ Crew execution finished.\")\n",
    "print(\"\\nCrew Final Result (Output of last task):\")\n",
    "print(\"========================================\")\n",
    "\n",
    "print_markdown(crew_result.raw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
